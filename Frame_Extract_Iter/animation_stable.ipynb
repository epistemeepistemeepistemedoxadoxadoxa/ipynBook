{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 21:09:01.971 Python[22890:1273330] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2025-03-25 21:09:01.971 Python[22890:1273330] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting registration mark detection...\n",
      "Registration mark detection failed: Not enough registration marks detected (found 0)\n",
      "Trying grid-based extraction...\n",
      "Grid-based extraction failed: OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n",
      "Attempting content-based extraction...\n",
      "Successfully extracted 36 frames using content-based approach\n",
      "Attempting registration mark detection...\n",
      "Registration mark detection failed: Not enough registration marks detected (found 0)\n",
      "Trying grid-based extraction...\n",
      "Successfully extracted 35 frames using grid-based approach\n",
      "Attempting registration mark detection...\n",
      "Registration mark detection failed: Not enough registration marks detected (found 1)\n",
      "Trying grid-based extraction...\n",
      "Grid-based extraction failed: OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n",
      "Attempting content-based extraction...\n",
      "Successfully extracted 28 frames using content-based approach\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import platform\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "from PIL import Image, ImageTk, ImageDraw, ImageFont, ImageOps\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import imageio\n",
    "import time\n",
    "import re\n",
    "import io\n",
    "import sys\n",
    "\n",
    "class PreciseFrameExtractor:\n",
    "    \"\"\"\n",
    "    A class specifically designed to extract frames from contact sheets with registration marks\n",
    "    at the corners of each frame. This implementation focuses on precise content extraction\n",
    "    and proper centering.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.debug_mode = False\n",
    "        self.min_frame_size = 100\n",
    "        self.max_frames = 50  # Changed from 100 to match expected frame count\n",
    "        self.registration_mark_size = 20\n",
    "        self.margin_percent = 0.05\n",
    "    \n",
    "    def set_debug_mode(self, debug):\n",
    "        \"\"\"Set debug mode.\"\"\"\n",
    "        self.debug_mode = debug\n",
    "    \n",
    "    def extract_frames(self, image, frames_per_row=None):\n",
    "        \"\"\"\n",
    "        Extract frames from a contact sheet image using multiple adaptive approaches.\n",
    "        \n",
    "        Args:\n",
    "            image: Input image (BGR format from OpenCV)\n",
    "            frames_per_row: Number of frames per row (auto-detected if None)\n",
    "            \n",
    "        Returns:\n",
    "            List of extracted frames as OpenCV images (BGR format)\n",
    "        \"\"\"\n",
    "        # Check if image is valid\n",
    "        if image is None or image.size == 0 or len(image.shape) < 2:\n",
    "            print(\"Warning: Invalid input image for frame extraction\")\n",
    "            return []\n",
    "            \n",
    "        # Create a copy for visualization if debug mode is on\n",
    "        debug_img = image.copy() if self.debug_mode else None\n",
    "        \n",
    "        # Try different approaches to extract frames\n",
    "        frames = []\n",
    "        \n",
    "        # Approach 1: Registration mark detection\n",
    "        print(\"Attempting registration mark detection...\")\n",
    "        try:\n",
    "            frames = self._extract_frames_from_registration_marks(image)\n",
    "            if frames and len(frames) >= 2:  # Need at least a couple of frames\n",
    "                print(f\"Successfully extracted {len(frames)} frames using registration mark detection\")\n",
    "                return frames\n",
    "        except Exception as e:\n",
    "            print(f\"Registration mark detection failed: {str(e)}\")\n",
    "        \n",
    "        # Approach 2: Grid-based extraction\n",
    "        print(\"Trying grid-based extraction...\")\n",
    "        try:\n",
    "            frames = self._extract_frames_grid_based(image, frames_per_row)\n",
    "            if frames and len(frames) >= 2:\n",
    "                print(f\"Successfully extracted {len(frames)} frames using grid-based approach\")\n",
    "                return frames\n",
    "        except Exception as e:\n",
    "            print(f\"Grid-based extraction failed: {str(e)}\")\n",
    "        \n",
    "        # Approach 3: Content-based extraction\n",
    "        print(\"Attempting content-based extraction...\")\n",
    "        try:\n",
    "            # Convert to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Try multiple thresholding methods\n",
    "            thresholds = [\n",
    "                # Binary threshold\n",
    "                lambda g: cv2.threshold(g, 220, 255, cv2.THRESH_BINARY_INV)[1],\n",
    "                # Adaptive threshold\n",
    "                lambda g: cv2.adaptiveThreshold(g, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                            cv2.THRESH_BINARY_INV, 21, 10),\n",
    "                # Otsu's threshold\n",
    "                lambda g: cv2.threshold(g, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "            ]\n",
    "            \n",
    "            content_frames = []\n",
    "            for threshold_func in thresholds:\n",
    "                if content_frames:\n",
    "                    break  # Stop if we already found frames\n",
    "                    \n",
    "                try:\n",
    "                    binary = threshold_func(gray)\n",
    "                    \n",
    "                    # Find contours\n",
    "                    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    \n",
    "                    # Determine reasonable size constraints based on image size\n",
    "                    height, width = image.shape[:2]\n",
    "                    min_area = (width * height) / 200  # Frames should be at least 0.5% of image\n",
    "                    max_area = (width * height) / 6    # Frames shouldn't be larger than 1/6 of image\n",
    "                    \n",
    "                    # Filter contours by size\n",
    "                    valid_contours = [c for c in contours if min_area < cv2.contourArea(c) < max_area]\n",
    "                    \n",
    "                    # Extract frames from valid contours\n",
    "                    for c in valid_contours:\n",
    "                        x, y, w, h = cv2.boundingRect(c)\n",
    "                        \n",
    "                        # Skip if aspect ratio is too extreme\n",
    "                        aspect_ratio = w / float(h)\n",
    "                        if aspect_ratio < 0.5 or aspect_ratio > 2:\n",
    "                            continue\n",
    "                        \n",
    "                        # Extract frame\n",
    "                        frame = image[y:y+h, x:x+w]\n",
    "                        \n",
    "                        # Center the frame\n",
    "                        frame = self._center_frame_cv2(frame)\n",
    "                        content_frames.append(frame)\n",
    "                        \n",
    "                        # Draw in debug mode\n",
    "                        if self.debug_mode and debug_img is not None:\n",
    "                            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "                except Exception as e:\n",
    "                    print(f\"Threshold method failed: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            if content_frames and len(content_frames) >= 2:\n",
    "                print(f\"Successfully extracted {len(content_frames)} frames using content-based approach\")\n",
    "                \n",
    "                # Save debug image\n",
    "                if self.debug_mode and debug_img is not None:\n",
    "                    cv2.imwrite(\"debug_content_extraction.jpg\", debug_img)\n",
    "                    \n",
    "                return content_frames\n",
    "        except Exception as e:\n",
    "            print(f\"Content-based extraction failed: {str(e)}\")\n",
    "        \n",
    "        # Approach 4: Simple division (last resort)\n",
    "        print(\"Falling back to simple division approach...\")\n",
    "        try:\n",
    "            # Use frames_per_row if provided, otherwise make a reasonable guess\n",
    "            cols = frames_per_row if frames_per_row else 4  # Default to 4 columns\n",
    "            \n",
    "            # Estimate rows based on image aspect ratio\n",
    "            height, width = image.shape[:2]\n",
    "            aspect_ratio = height / width\n",
    "            rows = max(1, int(cols * aspect_ratio * 0.75))  # Adjust for typical frame aspect ratios\n",
    "            \n",
    "            # Calculate margins and cell dimensions\n",
    "            margin_x = int(width * 0.05)  # 5% margin\n",
    "            margin_y = int(height * 0.05)  # 5% margin\n",
    "            cell_width = (width - 2 * margin_x) // cols\n",
    "            cell_height = (height - 2 * margin_y) // rows\n",
    "            \n",
    "            # Inner margin to exclude registration marks\n",
    "            inner_margin_percent = 0.15  # Default 15% inner margin\n",
    "            \n",
    "            simple_frames = []\n",
    "            for row in range(rows):\n",
    "                for col in range(cols):\n",
    "                    # Calculate frame coordinates\n",
    "                    x1 = margin_x + col * cell_width\n",
    "                    y1 = margin_y + row * cell_height\n",
    "                    x2 = x1 + cell_width\n",
    "                    y2 = y1 + cell_height\n",
    "                    \n",
    "                    # Apply inner margin\n",
    "                    inner_margin_x = int(cell_width * inner_margin_percent)\n",
    "                    inner_margin_y = int(cell_height * inner_margin_percent)\n",
    "                    \n",
    "                    x1 += inner_margin_x\n",
    "                    y1 += inner_margin_y\n",
    "                    x2 -= inner_margin_x\n",
    "                    y2 -= inner_margin_y\n",
    "                    \n",
    "                    # Ensure coordinates are within image bounds\n",
    "                    x1 = max(0, x1)\n",
    "                    y1 = max(0, y1)\n",
    "                    x2 = min(width, x2)\n",
    "                    y2 = min(height, y2)\n",
    "                    \n",
    "                    # Skip if resulting frame is too small\n",
    "                    if x2 - x1 < self.min_frame_size or y2 - y1 < self.min_frame_size:\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract frame\n",
    "                    frame = image[y1:y2, x1:x2]\n",
    "                    \n",
    "                    # Center the frame\n",
    "                    frame = self._center_frame_cv2(frame)\n",
    "                    simple_frames.append(frame)\n",
    "                    \n",
    "                    # Limit number of frames\n",
    "                    if len(simple_frames) >= self.max_frames:\n",
    "                        print(f\"Reached maximum frame limit of {self.max_frames}\")\n",
    "                        return simple_frames\n",
    "            \n",
    "            if simple_frames:\n",
    "                print(f\"Successfully extracted {len(simple_frames)} frames using simple division\")\n",
    "                return simple_frames\n",
    "        except Exception as e:\n",
    "            print(f\"Simple division failed: {str(e)}\")\n",
    "        \n",
    "        # If all approaches failed, return empty list\n",
    "        print(\"All extraction approaches failed\")\n",
    "        return []\n",
    "    \n",
    "    def _extract_frames_grid_based(self, img, frames_per_row=None):\n",
    "        \"\"\"\n",
    "        Extract frames using a precise grid-based approach with content-aware positioning.\n",
    "        \"\"\"\n",
    "        height, width = img.shape[:2]\n",
    "        \n",
    "        # Detect grid parameters\n",
    "        rows, cols, cell_width, cell_height, margin_x, margin_y = self._detect_grid_parameters(img, frames_per_row)\n",
    "        \n",
    "        if self.debug_mode:\n",
    "            print(f\"Detected grid: {rows}x{cols}, cell size: {cell_width}x{cell_height}, margins: {margin_x},{margin_y}\")\n",
    "            debug_img = img.copy()\n",
    "        \n",
    "        # Extract frames from grid\n",
    "        frames = []\n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                # Calculate cell boundaries\n",
    "                x1 = margin_x + col * cell_width\n",
    "                y1 = margin_y + row * cell_height\n",
    "                x2 = x1 + cell_width\n",
    "                y2 = y1 + cell_height\n",
    "                \n",
    "                # Ensure coordinates are within image bounds\n",
    "                x1 = max(0, x1)\n",
    "                y1 = max(0, y1)\n",
    "                x2 = min(width, x2)\n",
    "                y2 = min(height, y2)\n",
    "                \n",
    "                # Extract the cell\n",
    "                cell = img[y1:y2, x1:x2]\n",
    "                \n",
    "                # Find the actual content within the cell\n",
    "                gray_cell = cv2.cvtColor(cell, cv2.COLOR_BGR2GRAY)\n",
    "                _, binary = cv2.threshold(gray_cell, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "                \n",
    "                # Find contours of the content\n",
    "                contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                \n",
    "                # Find bounding box of all content\n",
    "                if contours:\n",
    "                    # Combine all contours to find the overall content area\n",
    "                    all_contours = np.vstack([contour for contour in contours])\n",
    "                    x, y, w, h = cv2.boundingRect(all_contours)\n",
    "                    \n",
    "                    # Add small margin around content\n",
    "                    margin = int(min(w, h) * 0.1)\n",
    "                    content_x1 = max(0, x - margin)\n",
    "                    content_y1 = max(0, y - margin)\n",
    "                    content_x2 = min(cell.shape[1], x + w + margin)\n",
    "                    content_y2 = min(cell.shape[0], y + h + margin)\n",
    "                    \n",
    "                    # Extract content if it's a reasonable size\n",
    "                    if w > cell.shape[1] * 0.1 and h > cell.shape[0] * 0.1:\n",
    "                        content = cell[content_y1:content_y2, content_x1:content_x2]\n",
    "                        \n",
    "                        # Center the content in a square canvas\n",
    "                        frame = self._center_frame_cv2(content)\n",
    "                        frames.append(frame)\n",
    "                        continue\n",
    "                \n",
    "                # If content detection failed, fall back to standard inner margin approach\n",
    "                inner_margin_percent = 0.22  # Increased to better exclude registration marks\n",
    "                inner_margin = int(min(cell_width, cell_height) * inner_margin_percent)\n",
    "                \n",
    "                # Apply inner margin\n",
    "                frame_x1 = x1 + inner_margin\n",
    "                frame_y1 = y1 + inner_margin\n",
    "                frame_x2 = x2 - inner_margin\n",
    "                frame_y2 = y2 - inner_margin\n",
    "                \n",
    "                # Ensure frame coordinates are valid\n",
    "                frame_x1 = max(0, frame_x1)\n",
    "                frame_y1 = max(0, frame_y1)\n",
    "                frame_x2 = min(width, frame_x2)\n",
    "                frame_y2 = min(height, frame_y2)\n",
    "                \n",
    "                # Skip if resulting frame is too small\n",
    "                if frame_x2 - frame_x1 < self.min_frame_size or frame_y2 - frame_y1 < self.min_frame_size:\n",
    "                    continue\n",
    "                \n",
    "                # Extract and center frame\n",
    "                frame = img[frame_y1:frame_y2, frame_x1:frame_x2]\n",
    "                frame = self._center_frame_cv2(frame)\n",
    "                frames.append(frame)\n",
    "        \n",
    "        return frames\n",
    "\n",
    "\n",
    "    \n",
    "    def _detect_circular_marks(self, img):\n",
    "        \"\"\"Specifically detect circular registration marks with improved parameters.\"\"\"\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)  # Reduced kernel size for finer details\n",
    "        \n",
    "        # Adjusted parameters based on your specific registration marks\n",
    "        circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1.5,  # Reduced dp for more precision\n",
    "                                minDist=50,  # Decreased minimum distance\n",
    "                                param1=100,   # Reduced edge detection threshold\n",
    "                                param2=50,    # Reduced accumulator threshold to detect more circles\n",
    "                                minRadius=10, # Reduced min radius to catch smaller marks\n",
    "                                maxRadius=30) # Adjusted max radius\n",
    "        \n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))\n",
    "            # Limit to a reasonable number of circles\n",
    "            max_circles = 100  # Increased maximum circles\n",
    "            if len(circles[0]) > max_circles:\n",
    "                # Take only the strongest matches if too many are found\n",
    "                circles = np.array([circles[0][:max_circles]])\n",
    "            return [(x, y) for x, y, r in circles[0, :]]\n",
    "        return []\n",
    "\n",
    "    def _detect_grid_parameters(self, img, frames_per_row=None):\n",
    "        \"\"\"\n",
    "        Improved detection of grid parameters for better frame extraction.\n",
    "        \"\"\"\n",
    "        height, width = img.shape[:2]\n",
    "        \n",
    "        # Convert to grayscale and threshold\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Try multiple thresholding approaches for better detection\n",
    "        binary = None\n",
    "        thresholds = [\n",
    "            lambda g: cv2.threshold(g, 200, 255, cv2.THRESH_BINARY_INV)[1],\n",
    "            lambda g: cv2.adaptiveThreshold(g, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2),\n",
    "            lambda g: cv2.threshold(g, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "        ]\n",
    "        \n",
    "        valid_contours = []\n",
    "        for threshold_func in thresholds:\n",
    "            try:\n",
    "                binary = threshold_func(gray)\n",
    "                \n",
    "                # Find contours\n",
    "                contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                \n",
    "                # Filter contours by size\n",
    "                min_contour_area = (width * height) / 2000  # Reduced for smaller frames\n",
    "                temp_valid_contours = [c for c in contours if cv2.contourArea(c) > min_contour_area]\n",
    "                \n",
    "                if len(temp_valid_contours) >= 4:\n",
    "                    valid_contours = temp_valid_contours\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"Threshold method failed: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Calculate grid parameters based on contour distribution\n",
    "        if len(valid_contours) >= 4:\n",
    "            # Get bounding boxes and their centers\n",
    "            bboxes = [cv2.boundingRect(c) for c in valid_contours]\n",
    "            centers = [(x + w//2, y + h//2) for (x, y, w, h) in bboxes]\n",
    "            \n",
    "            # Cluster centers to find rows and columns\n",
    "            y_coords = np.array([c[1] for c in centers]).reshape(-1, 1)\n",
    "            # Use a smaller eps for more precise row detection\n",
    "            row_clustering = DBSCAN(eps=height/30, min_samples=1).fit(y_coords)\n",
    "            \n",
    "            # Calculate row count from unique labels\n",
    "            unique_rows = len(np.unique(row_clustering.labels_))\n",
    "            rows = unique_rows\n",
    "            \n",
    "            # Calculate column count using x-coordinate clustering\n",
    "            if frames_per_row is None:\n",
    "                x_coords = np.array([c[0] for c in centers]).reshape(-1, 1)\n",
    "                # Use a smaller eps for more precise column detection\n",
    "                col_clustering = DBSCAN(eps=width/30, min_samples=1).fit(x_coords)\n",
    "                cols = len(np.unique(col_clustering.labels_))\n",
    "            else:\n",
    "                cols = frames_per_row\n",
    "            \n",
    "            # Calculate cell size based on median dimensions with adjustment\n",
    "            widths = [w for (x, y, w, h) in bboxes]\n",
    "            heights = [h for (x, y, w, h) in bboxes]\n",
    "            \n",
    "            # Use percentile instead of median for more robust estimation\n",
    "            # 75th percentile gives a better estimate for cell size\n",
    "            cell_width = int(np.percentile(widths, 75) * 1.6)  # Increased multiplier\n",
    "            cell_height = int(np.percentile(heights, 75) * 1.6)\n",
    "            \n",
    "            # Calculate dynamic margins\n",
    "            margin_x = max(20, int((width - (cols * cell_width)) / 2))\n",
    "            margin_y = max(20, int((height - (rows * cell_height)) / 2))\n",
    "            \n",
    "            return rows, cols, cell_width, cell_height, margin_x, margin_y\n",
    "        \n",
    "        # Fallback to aspect ratio estimation - improved with better defaults\n",
    "        aspect_ratio = width / height\n",
    "        \n",
    "        # Let's handle a special case for your specific contact sheet shown in the image\n",
    "        # It appears to be a 4x4 grid (or similar)\n",
    "        if frames_per_row is None:\n",
    "            # Default to 4 columns if your contact sheet typically has 4 columns\n",
    "            cols = 4\n",
    "        else:\n",
    "            cols = frames_per_row\n",
    "            \n",
    "        # Calculate rows based on aspect ratio\n",
    "        # For the sample shown, it looks like there are multiple rows\n",
    "        rows = int((cols * height) / (width * aspect_ratio))\n",
    "        # Ensure we have at least 2 rows\n",
    "        rows = max(2, rows)\n",
    "        \n",
    "        # Calculate cell size with improved margins\n",
    "        margin_x = int(width * 0.05)\n",
    "        margin_y = int(height * 0.05)\n",
    "        cell_width = (width - 2 * margin_x) // cols\n",
    "        cell_height = (height - 2 * margin_y) // rows\n",
    "        \n",
    "        return rows, cols, cell_width, cell_height, margin_x, margin_y\n",
    "    \n",
    "            \n",
    "    def _extract_frames_from_registration_marks(self, img):\n",
    "        \"\"\"Extract frames by detecting registration marks with adaptive parameter selection.\"\"\"\n",
    "        height, width = img.shape[:2]\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Create a debug image if debug mode is on\n",
    "        debug_img = img.copy() if self.debug_mode else None\n",
    "        \n",
    "        # Try multiple thresholds to improve registration mark detection\n",
    "        all_reg_mark_centers = []\n",
    "        \n",
    "        # Use adaptive thresholds based on image characteristics\n",
    "        mean_val = np.mean(gray)\n",
    "        std_val = np.std(gray)\n",
    "        \n",
    "        # Dynamic thresholds based on image statistics\n",
    "        thresholds = [\n",
    "            # Brighter threshold for light images\n",
    "            lambda g: cv2.threshold(g, min(mean_val + std_val, 200), 255, cv2.THRESH_BINARY_INV)[1],\n",
    "            # Middle threshold\n",
    "            lambda g: cv2.threshold(g, mean_val, 255, cv2.THRESH_BINARY_INV)[1],\n",
    "            # Darker threshold for dark images\n",
    "            lambda g: cv2.threshold(g, max(mean_val - std_val, 50), 255, cv2.THRESH_BINARY_INV)[1],\n",
    "            # Adaptive threshold\n",
    "            lambda g: cv2.adaptiveThreshold(g, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                        cv2.THRESH_BINARY_INV, 11, 2),\n",
    "            # Otsu's threshold\n",
    "            lambda g: cv2.threshold(g, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "        ]\n",
    "        \n",
    "        for threshold_func in thresholds:\n",
    "            try:\n",
    "                binary = threshold_func(gray)\n",
    "                \n",
    "                # Find contours\n",
    "                contours, _ = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                \n",
    "                # Calculate dynamic size limits based on image dimensions\n",
    "                min_area = (width * height) / 10000  # Adaptive minimum size\n",
    "                max_area = (width * height) / 200    # Adaptive maximum size\n",
    "                \n",
    "                # Filter contours by size and shape\n",
    "                for c in contours:\n",
    "                    area = cv2.contourArea(c)\n",
    "                    \n",
    "                    if area < min_area or area > max_area:\n",
    "                        continue\n",
    "                    \n",
    "                    # Check if contour is circular or square (registration marks can be either)\n",
    "                    perimeter = cv2.arcLength(c, True)\n",
    "                    if perimeter == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    circularity = 4 * np.pi * area / (perimeter * perimeter)\n",
    "                    # Accept shapes that are somewhat circular or square (0.5-0.9 covers most marks)\n",
    "                    if 0.5 <= circularity <= 0.9:\n",
    "                        # Get center of contour\n",
    "                        M = cv2.moments(c)\n",
    "                        if M[\"m00\"] != 0:\n",
    "                            cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "                            cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "                            all_reg_mark_centers.append((cx, cy))\n",
    "                            \n",
    "                            # Draw in debug mode\n",
    "                            if self.debug_mode and debug_img is not None:\n",
    "                                cv2.drawContours(debug_img, [c], -1, (0, 0, 255), 2)\n",
    "                                cv2.circle(debug_img, (cx, cy), 3, (255, 0, 0), -1)\n",
    "            except Exception as e:\n",
    "                print(f\"Threshold method failed: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Remove duplicate centers\n",
    "        unique_centers = []\n",
    "        for center in all_reg_mark_centers:\n",
    "            is_duplicate = False\n",
    "            for unique in unique_centers:\n",
    "                # Dynamic distance threshold based on image size\n",
    "                distance_threshold = min(width, height) / 100\n",
    "                if math.sqrt((center[0] - unique[0])**2 + (center[1] - unique[1])**2) < distance_threshold:\n",
    "                    is_duplicate = True\n",
    "                    break\n",
    "            if not is_duplicate:\n",
    "                unique_centers.append(center)\n",
    "        \n",
    "        if len(unique_centers) < 4:\n",
    "            raise ValueError(f\"Not enough registration marks detected (found {len(unique_centers)})\")\n",
    "        \n",
    "        # Group centers into frames using DBSCAN with adaptive epsilon\n",
    "        frames = []\n",
    "        centers_array = np.array(unique_centers)\n",
    "        \n",
    "        # Estimate epsilon based on image size and mark distribution\n",
    "        # Find min distance between points to estimate mark spacing\n",
    "        all_dists = []\n",
    "        for i in range(len(unique_centers)):\n",
    "            for j in range(i+1, len(unique_centers)):\n",
    "                dist = math.sqrt((unique_centers[i][0] - unique_centers[j][0])**2 + \n",
    "                            (unique_centers[i][1] - unique_centers[j][1])**2)\n",
    "                all_dists.append(dist)\n",
    "        \n",
    "        # Sort distances and get the smallest ones (likely within same frame)\n",
    "        if all_dists:\n",
    "            all_dists.sort()\n",
    "            # Use a percentile approach to estimate frame size\n",
    "            frame_size_est = np.percentile(all_dists, 75)\n",
    "            epsilon = frame_size_est * 1.2  # Epsilon slightly larger than estimated frame size\n",
    "        else:\n",
    "            # Fallback if no distances calculated\n",
    "            epsilon = min(width, height) / 5\n",
    "        \n",
    "        # Adjust min_samples based on expected frame structure\n",
    "        # 4 corners = 4 marks, but we'll accept 3 to handle partial marks\n",
    "        min_samples = 3\n",
    "        \n",
    "        # Perform clustering\n",
    "        clustering = DBSCAN(eps=epsilon, min_samples=min_samples).fit(centers_array)\n",
    "        \n",
    "        # Get unique labels\n",
    "        labels = clustering.labels_\n",
    "        unique_labels = set(labels)\n",
    "        \n",
    "        # Process clusters to find frames\n",
    "        for label in unique_labels:\n",
    "            if label == -1:  # Skip noise points\n",
    "                continue\n",
    "                \n",
    "            # Get points in this cluster\n",
    "            cluster_points = centers_array[labels == label]\n",
    "            points = [(int(p[0]), int(p[1])) for p in cluster_points]\n",
    "            \n",
    "            # We need at least 3 points to estimate a frame\n",
    "            if len(points) < 3:\n",
    "                continue\n",
    "            \n",
    "            # For 3 or more points, estimate a rectangular frame\n",
    "            # We'll use convex hull and minimum area rectangle\n",
    "            hull = cv2.convexHull(np.array(points))\n",
    "            rect = cv2.minAreaRect(hull)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "            frame_corners = [tuple(p) for p in box]\n",
    "            \n",
    "            # Sort the corners (top-left, top-right, bottom-right, bottom-left)\n",
    "            sorted_corners = self._sort_points(frame_corners)\n",
    "            \n",
    "            # Calculate inner margin based on frame size\n",
    "            width_points = int((sorted_corners[1][0] - sorted_corners[0][0] + \n",
    "                            sorted_corners[2][0] - sorted_corners[3][0]) / 2)\n",
    "            height_points = int((sorted_corners[3][1] - sorted_corners[0][1] + \n",
    "                            sorted_corners[2][1] - sorted_corners[1][1]) / 2)\n",
    "            \n",
    "            # Use adaptive inner margin based on frame size\n",
    "            inner_margin_percent = 0.15  # Default value\n",
    "            \n",
    "            # Calculate frame boundaries\n",
    "            center_x = int(sum(p[0] for p in sorted_corners) / 4)\n",
    "            center_y = int(sum(p[1] for p in sorted_corners) / 4)\n",
    "            \n",
    "            frame_width = int(width_points * (1 - 2 * inner_margin_percent))\n",
    "            frame_height = int(height_points * (1 - 2 * inner_margin_percent))\n",
    "            \n",
    "            x1 = center_x - frame_width // 2\n",
    "            y1 = center_y - frame_height // 2\n",
    "            x2 = x1 + frame_width\n",
    "            y2 = y1 + frame_height\n",
    "            \n",
    "            # Draw in debug mode\n",
    "            if self.debug_mode and debug_img is not None:\n",
    "                for p in sorted_corners:\n",
    "                    cv2.circle(debug_img, p, 5, (0, 255, 0), -1)\n",
    "                cv2.rectangle(debug_img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            \n",
    "            # Ensure coordinates are within image bounds\n",
    "            x1 = max(0, x1)\n",
    "            y1 = max(0, y1)\n",
    "            x2 = min(width, x2)\n",
    "            y2 = min(height, y2)\n",
    "            \n",
    "            # Skip if resulting frame is too small\n",
    "            min_size = min(width, height) / 20  # Adaptive minimum size\n",
    "            if x2 - x1 < min_size or y2 - y1 < min_size:\n",
    "                continue\n",
    "            \n",
    "            # Extract and center frame\n",
    "            frame = img[y1:y2, x1:x2]\n",
    "            frame = self._center_frame_cv2(frame)\n",
    "            frames.append(frame)\n",
    "        \n",
    "        # Save debug image\n",
    "        if self.debug_mode and debug_img is not None:\n",
    "            cv2.imwrite(\"debug_registration_marks.jpg\", debug_img)\n",
    "        \n",
    "        return frames\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _sort_points(self, points):\n",
    "        \"\"\"Sort points in order: top-left, top-right, bottom-right, bottom-left.\"\"\"\n",
    "        # Sort points based on x-coordinate first\n",
    "        points = sorted(points, key=lambda p: p[0])\n",
    "        \n",
    "        # Get the left points (first 2) and right points (last 2)\n",
    "        left_points = points[:2]\n",
    "        right_points = points[2:] if len(points) >= 4 else points[1:]\n",
    "        \n",
    "        # Sort left points by y-coordinate\n",
    "        left_points = sorted(left_points, key=lambda p: p[1])\n",
    "        top_left, bottom_left = left_points if len(left_points) >= 2 else (left_points[0], left_points[0])\n",
    "        \n",
    "        # Sort right points by y-coordinate\n",
    "        right_points = sorted(right_points, key=lambda p: p[1])\n",
    "        top_right, bottom_right = right_points if len(right_points) >= 2 else (right_points[0], right_points[0])\n",
    "        \n",
    "        return [top_left, top_right, bottom_right, bottom_left]\n",
    "\n",
    "\n",
    "    def _is_rectangle(self, points):\n",
    "        \"\"\"Check if points form a rectangle with adaptive tolerance.\"\"\"\n",
    "        if len(points) != 4:\n",
    "            return False\n",
    "        \n",
    "        # Calculate pairwise distances between points\n",
    "        distances = []\n",
    "        for i in range(len(points)):\n",
    "            for j in range(i+1, len(points)):\n",
    "                dx = points[i][0] - points[j][0]\n",
    "                dy = points[i][1] - points[j][1]\n",
    "                distances.append(math.sqrt(dx*dx + dy*dy))\n",
    "        \n",
    "        # Sort distances\n",
    "        distances.sort()\n",
    "        \n",
    "        # For a rectangle, we should have 4 equal sides and 2 equal diagonals\n",
    "        if len(distances) != 6:  # Should have exactly 6 distances for 4 points\n",
    "            return False\n",
    "        \n",
    "        # Group similar distances (sides and diagonals)\n",
    "        # Use a hierarchical approach to group similar distances\n",
    "        from scipy.cluster.hierarchy import linkage, fcluster\n",
    "        \n",
    "        # Convert to numpy array for clustering\n",
    "        distances_array = np.array(distances).reshape(-1, 1)\n",
    "        \n",
    "        # Perform hierarchical clustering on distances\n",
    "        if len(distances_array) >= 2:  # Need at least 2 distances for clustering\n",
    "            Z = linkage(distances_array, 'single')\n",
    "            # Try to cluster into 2 groups (sides and diagonals)\n",
    "            try:\n",
    "                clusters = fcluster(Z, 2, criterion='maxclust')\n",
    "                # Count elements in each cluster\n",
    "                counts = np.bincount(clusters)\n",
    "                # For a rectangle: one cluster should have 4 elements (sides), other should have 2 (diagonals)\n",
    "                if len(counts) > 1 and (counts[0] == 4 and counts[1] == 2 or counts[0] == 2 and counts[1] == 4):\n",
    "                    return True\n",
    "            except:\n",
    "                # Fall back to simpler approach if clustering fails\n",
    "                pass\n",
    "        \n",
    "        # Fallback approach: check variance within sides and diagonals\n",
    "        sides = distances[:4]\n",
    "        diagonals = distances[4:]\n",
    "        \n",
    "        # Calculate variance within sides and diagonals\n",
    "        sides_mean = sum(sides) / len(sides)\n",
    "        sides_variance = sum((x - sides_mean) ** 2 for x in sides) / len(sides)\n",
    "        sides_relative_variance = sides_variance / (sides_mean ** 2)\n",
    "        \n",
    "        diagonals_mean = sum(diagonals) / len(diagonals)\n",
    "        diagonals_variance = sum((x - diagonals_mean) ** 2 for x in diagonals) / len(diagonals)\n",
    "        diagonals_relative_variance = diagonals_variance / (diagonals_mean ** 2)\n",
    "        \n",
    "        # Adaptive tolerance based on image characteristics\n",
    "        # For a perfect rectangle, both variances would be 0\n",
    "        # Allow more variance for real-world images with perspective distortion\n",
    "        if sides_relative_variance < 0.1 and diagonals_relative_variance < 0.1:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "\n",
    "    \n",
    "    def _extract_frames_simple_division(self, img, frames_per_row):\n",
    "        \"\"\"\n",
    "        Extract frames by simply dividing the image into a grid.\n",
    "        \"\"\"\n",
    "        height, width = img.shape[:2]\n",
    "        \n",
    "        # Estimate total frames (assume 9 rows x 4 columns = 36 frames by default)\n",
    "        total_frames = 36\n",
    "        rows = total_frames // frames_per_row\n",
    "        \n",
    "        # Calculate cell size and margins\n",
    "        margin_percent = 0.05  # 5% margin\n",
    "        margin_x = int(width * margin_percent)\n",
    "        margin_y = int(height * margin_percent)\n",
    "        cell_width = (width - 2 * margin_x) // frames_per_row\n",
    "        cell_height = (height - 2 * margin_y) // rows\n",
    "        \n",
    "        # Extract frames from grid\n",
    "        frames = []\n",
    "        for row in range(rows):\n",
    "            for col in range(frames_per_row):\n",
    "                # Calculate frame coordinates with margins\n",
    "                x1 = margin_x + col * cell_width\n",
    "                y1 = margin_y + row * cell_height\n",
    "                x2 = x1 + cell_width\n",
    "                y2 = y1 + cell_height\n",
    "                \n",
    "                # Add inner margin to exclude registration marks\n",
    "                inner_margin = int(min(cell_width, cell_height) * 0.1)\n",
    "                x1 += inner_margin\n",
    "                y1 += inner_margin\n",
    "                x2 -= inner_margin\n",
    "                y2 -= inner_margin\n",
    "                \n",
    "                # Ensure coordinates are within image bounds\n",
    "                x1 = max(0, x1)\n",
    "                y1 = max(0, y1)\n",
    "                x2 = min(width, x2)\n",
    "                y2 = min(height, y2)\n",
    "                \n",
    "                # Skip if resulting frame is too small\n",
    "                if x2 - x1 < self.min_frame_size or y2 - y1 < self.min_frame_size:\n",
    "                    continue\n",
    "                \n",
    "                # Extract frame\n",
    "                frame = img[y1:y2, x1:x2]\n",
    "                \n",
    "                # Center the frame in a square canvas\n",
    "                frame = self._center_frame_cv2(frame)\n",
    "                \n",
    "                frames.append(frame)\n",
    "                \n",
    "                # Limit number of frames\n",
    "                if len(frames) >= self.max_frames:\n",
    "                    return frames\n",
    "        \n",
    "        return frames\n",
    "            \n",
    "    def _center_frame_cv2(self, frame):\n",
    "        \"\"\"Center the frame content in a square canvas with white background.\"\"\"\n",
    "        if frame is None or frame.size == 0:\n",
    "            return None\n",
    "            \n",
    "        # Get frame dimensions\n",
    "        height, width = frame.shape[:2]\n",
    "        \n",
    "        # Find the actual content boundaries\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        _, binary = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "        # Find contours to identify content areas\n",
    "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Determine where to place the frame based on content\n",
    "        content_x1, content_y1, content_width, content_height = 0, 0, width, height\n",
    "        \n",
    "        if contours:\n",
    "            # Find bounding rectangle of all content\n",
    "            all_contours = np.vstack([contour for contour in contours])\n",
    "            content_x1, content_y1, content_width, content_height = cv2.boundingRect(all_contours)\n",
    "        \n",
    "        # Determine the size of the square canvas (max of content width and height plus padding)\n",
    "        max_content_dim = max(content_width, content_height)\n",
    "        padding = int(max_content_dim * 0.2)  # 20% padding\n",
    "        canvas_size = max_content_dim + 2 * padding\n",
    "        \n",
    "        # Create a new square image with white background\n",
    "        centered_frame = np.ones((canvas_size, canvas_size, 3), dtype=np.uint8) * 255\n",
    "        \n",
    "        # Calculate position to paste the content (centered)\n",
    "        paste_x = (canvas_size - content_width) // 2\n",
    "        paste_y = (canvas_size - content_height) // 2\n",
    "        \n",
    "        # Paste the content onto the canvas\n",
    "        if content_width > 0 and content_height > 0:\n",
    "            content = frame[content_y1:content_y1+content_height, content_x1:content_x1+content_width]\n",
    "            centered_frame[paste_y:paste_y+content_height, paste_x:paste_x+content_width] = content\n",
    "        \n",
    "        return centered_frame\n",
    "\n",
    "\n",
    "\n",
    "    def _visualize_extraction(self, img, centers, frames, filename=\"debug_extraction.jpg\"):\n",
    "        \"\"\"\n",
    "        Create a visualization of the extraction process for debugging.\n",
    "        \n",
    "        Args:\n",
    "            img: Original image\n",
    "            centers: List of detected registration mark centers\n",
    "            frames: List of extracted frame boundaries [(x1,y1,x2,y2), ...]\n",
    "            filename: Output filename for the debug image\n",
    "        \"\"\"\n",
    "        if not self.debug_mode:\n",
    "            return\n",
    "            \n",
    "        debug_img = img.copy()\n",
    "        \n",
    "        # Draw all detected registration mark centers\n",
    "        for center in centers:\n",
    "            cv2.circle(debug_img, center, 5, (0, 0, 255), -1)\n",
    "        \n",
    "        # Draw frame boundaries\n",
    "        for i, (x1, y1, x2, y2) in enumerate(frames):\n",
    "            cv2.rectangle(debug_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(debug_img, f\"{i+1}\", (x1+10, y1+30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        \n",
    "        # Save the debug image\n",
    "        cv2.imwrite(filename, debug_img)\n",
    "\n",
    "class AnimationApp:\n",
    "    \"\"\"\n",
    "    Application for extracting frames from contact sheets and creating animations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Animation Extractor\")\n",
    "        \n",
    "        # Set up variables\n",
    "        self.contact_sheet = None\n",
    "        self.extracted_frames = []\n",
    "        self.current_frame_index = 0\n",
    "        self.is_playing = False\n",
    "        self.play_after_id = None\n",
    "        \n",
    "        # Create UI variables\n",
    "        self.status_var = tk.StringVar(value=\"Ready\")\n",
    "        self.frame_rate = tk.DoubleVar(value=12.0)  # Default 12 FPS\n",
    "        self.frames_per_row = tk.IntVar(value=4)  # Default 4 frames per row\n",
    "        self.extraction_mode = tk.StringVar(value=\"auto\")  # Default to auto mode\n",
    "        self.registration_mark_threshold = tk.IntVar(value=70)  # Default 70%\n",
    "        self.debug_mode = tk.BooleanVar(value=False)  # Debug mode toggle\n",
    "        \n",
    "        # Create main frame\n",
    "        main_frame = ttk.Frame(root, padding=\"10\")\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Create left panel for controls\n",
    "        control_frame = ttk.Frame(main_frame, padding=\"5\", width=200)\n",
    "        control_frame.pack(side=tk.LEFT, fill=tk.Y, padx=(0, 10))\n",
    "        \n",
    "        # Create right panel for image display\n",
    "        display_frame = ttk.Frame(main_frame)\n",
    "        display_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Create canvas for image display\n",
    "        self.canvas = tk.Canvas(display_frame, bg=\"#f0f0f0\", highlightthickness=0)\n",
    "        self.canvas.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Input section\n",
    "        input_frame = ttk.LabelFrame(control_frame, text=\"Input\", padding=\"5\")\n",
    "        input_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        ttk.Button(input_frame, text=\"Load Contact Sheet\", command=self.load_contact_sheet).pack(fill=tk.X)\n",
    "        ttk.Button(input_frame, text=\"Extract Frames\", command=self.extract_frames_from_registration_marks).pack(fill=tk.X, pady=(5, 0))\n",
    "        \n",
    "        # Extraction mode section\n",
    "        mode_frame = ttk.LabelFrame(control_frame, text=\"Extraction Settings\", padding=\"5\")\n",
    "        mode_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        # Mode selection\n",
    "        ttk.Label(mode_frame, text=\"Mode:\").pack(anchor=tk.W)\n",
    "        ttk.Radiobutton(mode_frame, text=\"Auto\", variable=self.extraction_mode, value=\"auto\").pack(anchor=tk.W)\n",
    "        ttk.Radiobutton(mode_frame, text=\"Digital\", variable=self.extraction_mode, value=\"digital\").pack(anchor=tk.W)\n",
    "        ttk.Radiobutton(mode_frame, text=\"RISO Print\", variable=self.extraction_mode, value=\"riso\").pack(anchor=tk.W)\n",
    "        \n",
    "        # Frames per row setting\n",
    "        ttk.Label(mode_frame, text=\"Frames Per Row:\").pack(anchor=tk.W, pady=(5, 0))\n",
    "        ttk.Spinbox(mode_frame, from_=1, to=20, textvariable=self.frames_per_row, width=5).pack(anchor=tk.W)\n",
    "        \n",
    "        # Registration mark threshold\n",
    "        ttk.Label(mode_frame, text=\"Registration Mark Threshold (%):\").pack(anchor=tk.W, pady=(5, 0))\n",
    "        ttk.Spinbox(mode_frame, from_=10, to=90, textvariable=self.registration_mark_threshold, width=5).pack(anchor=tk.W)\n",
    "        \n",
    "        # Debug mode toggle\n",
    "        ttk.Checkbutton(mode_frame, text=\"Debug Mode\", variable=self.debug_mode).pack(anchor=tk.W, pady=(5, 0))\n",
    "        \n",
    "        # Extract button\n",
    "        ttk.Button(mode_frame, text=\"Extract Frames\", command=self.extract_frames_from_registration_marks).pack(fill=tk.X, pady=(5, 0))\n",
    "        \n",
    "        # Playback controls\n",
    "        playback_frame = ttk.LabelFrame(control_frame, text=\"Playback\", padding=\"5\")\n",
    "        playback_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        # Frame rate control\n",
    "        ttk.Label(playback_frame, text=\"Frame Rate (FPS):\").pack(anchor=tk.W)\n",
    "        ttk.Spinbox(playback_frame, from_=1, to=60, textvariable=self.frame_rate, width=5).pack(anchor=tk.W, pady=(0, 5))\n",
    "        \n",
    "        # Playback buttons\n",
    "        button_frame = ttk.Frame(playback_frame)\n",
    "        button_frame.pack(fill=tk.X)\n",
    "        \n",
    "        ttk.Button(button_frame, text=\"⏮\", width=3, command=self.go_to_first_frame).pack(side=tk.LEFT)\n",
    "        ttk.Button(button_frame, text=\"⏪\", width=3, command=self.previous_frame).pack(side=tk.LEFT)\n",
    "        self.play_button = ttk.Button(button_frame, text=\"▶\", width=3, command=self.toggle_playback)\n",
    "        self.play_button.pack(side=tk.LEFT)\n",
    "        ttk.Button(button_frame, text=\"⏩\", width=3, command=self.next_frame).pack(side=tk.LEFT)\n",
    "        ttk.Button(button_frame, text=\"⏭\", width=3, command=self.go_to_last_frame).pack(side=tk.LEFT)\n",
    "        \n",
    "        # Export section\n",
    "        export_frame = ttk.LabelFrame(control_frame, text=\"Export\", padding=\"5\")\n",
    "        export_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        ttk.Button(export_frame, text=\"Export as GIF\", command=self.export_as_gif).pack(fill=tk.X)\n",
    "        ttk.Button(export_frame, text=\"Export as MP4\", command=self.export_as_mp4).pack(fill=tk.X, pady=(5, 0))\n",
    "        ttk.Button(export_frame, text=\"Export Frames\", command=self.export_frames).pack(fill=tk.X, pady=(5, 0))\n",
    "        \n",
    "        # Status bar\n",
    "        status_bar = ttk.Label(root, textvariable=self.status_var, relief=tk.SUNKEN, anchor=tk.W)\n",
    "        status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        \n",
    "        # Bind keyboard shortcuts\n",
    "        self.root.bind(\"<Left>\", lambda e: self.previous_frame())\n",
    "        self.root.bind(\"<Right>\", lambda e: self.next_frame())\n",
    "        self.root.bind(\"<space>\", lambda e: self.toggle_playback())\n",
    "        \n",
    "        # Initialize the display\n",
    "        self.display_placeholder()\n",
    "    \n",
    "    def load_contact_sheet(self):\n",
    "        \"\"\"Load a contact sheet image.\"\"\"\n",
    "        try:\n",
    "            # Use tkinter file dialog with explicit initialdir to avoid None issues\n",
    "            file_path = filedialog.askopenfilename(\n",
    "                title=\"Select Contact Sheet\",\n",
    "                initialdir=\".\",  # Start in current directory\n",
    "                filetypes=[\n",
    "                    (\"Image files\", \"*.png *.jpg *.jpeg *.tif *.tiff *.bmp\"),\n",
    "                    (\"PDF files\", \"*.pdf\"),\n",
    "                    (\"All files\", \"*.*\")\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Check if file_path is not empty (user didn't cancel)\n",
    "            if file_path and os.path.exists(file_path):\n",
    "                try:\n",
    "                    # Load the image\n",
    "                    if file_path.lower().endswith('.pdf'):\n",
    "                        # Convert PDF to image\n",
    "                        try:\n",
    "                            from pdf2image import convert_from_path\n",
    "                            images = convert_from_path(file_path, dpi=300, first_page=1, last_page=1)\n",
    "                            if images and len(images) > 0:\n",
    "                                self.contact_sheet = images[0]\n",
    "                            else:\n",
    "                                raise ValueError(\"Failed to convert PDF to image\")\n",
    "                        except ImportError:\n",
    "                            # Fallback to using pdftoppm via subprocess\n",
    "                            with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                                temp_prefix = os.path.join(temp_dir, \"pdf_page\")\n",
    "                                result = subprocess.run([\"pdftoppm\", \"-png\", \"-f\", \"1\", \"-l\", \"1\", file_path, temp_prefix], \n",
    "                                                    capture_output=True, check=False)\n",
    "                                \n",
    "                                if result.returncode != 0:\n",
    "                                    raise ValueError(f\"PDF conversion failed: {result.stderr.decode('utf-8', errors='ignore')}\")\n",
    "                                    \n",
    "                                # Find the generated PNG file\n",
    "                                png_files = [f for f in os.listdir(temp_dir) if f.endswith(\".png\")]\n",
    "                                if not png_files:\n",
    "                                    raise ValueError(\"No PNG files generated from PDF\")\n",
    "                                    \n",
    "                                img_path = os.path.join(temp_dir, png_files[0])\n",
    "                                self.contact_sheet = Image.open(img_path)\n",
    "                    else:\n",
    "                        # Load regular image file\n",
    "                        self.contact_sheet = Image.open(file_path)\n",
    "                    \n",
    "                    # Update status\n",
    "                    self.status_var.set(f\"Loaded contact sheet: {os.path.basename(file_path)}\")\n",
    "                    \n",
    "                    # Display the contact sheet\n",
    "                    self.display_contact_sheet()\n",
    "                    \n",
    "                    # Clear any existing frames\n",
    "                    self.extracted_frames = []\n",
    "                    self.current_frame_index = 0\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    messagebox.showerror(\"Error\", f\"Error loading contact sheet: {str(e)}\")\n",
    "                    \n",
    "            elif file_path:  # Path selected but doesn't exist\n",
    "                messagebox.showerror(\"Error\", f\"File not found: {file_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            # Catch any exceptions in the file dialog itself\n",
    "            messagebox.showerror(\"Error\", f\"File dialog error: {str(e)}\")\n",
    "            print(f\"File dialog error: {str(e)}\")\n",
    "    ##\n",
    "    def extract_frames_from_registration_marks(self):\n",
    "        \"\"\"Extract frames from a contact sheet using registration mark detection.\"\"\"\n",
    "        if self.contact_sheet is None:\n",
    "            messagebox.showwarning(\"Warning\", \"No contact sheet loaded\")\n",
    "            return\n",
    "                \n",
    "        try:\n",
    "            # Convert PIL Image to OpenCV format\n",
    "            cv_image = cv2.cvtColor(np.array(self.contact_sheet), cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Create frame extractor\n",
    "            extractor = PreciseFrameExtractor()\n",
    "            \n",
    "            # Set debug mode if needed\n",
    "            extractor.set_debug_mode(self.debug_mode.get())\n",
    "            \n",
    "            # Extract frames - this will now prioritize registration mark detection\n",
    "            frames = extractor.extract_frames(cv_image, self.frames_per_row.get())\n",
    "            \n",
    "            if not frames:\n",
    "                messagebox.showwarning(\"Warning\", \"No frames could be extracted\")\n",
    "                return\n",
    "            \n",
    "            # Convert OpenCV frames back to PIL format\n",
    "            pil_frames = []\n",
    "            for frame in frames:\n",
    "                # Verify frame is valid before conversion\n",
    "                if frame is None or frame.size == 0 or frame.shape[0] <= 0 or frame.shape[1] <= 0:\n",
    "                    print(\"Skipping invalid frame during conversion\")\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    pil_frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                    pil_frames.append(pil_frame)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error converting frame: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            # Update the extracted frames\n",
    "            self.extracted_frames = pil_frames\n",
    "            self.current_frame_index = 0\n",
    "            \n",
    "            # Display the first frame if available\n",
    "            if self.extracted_frames:\n",
    "                self.display_current_frame()\n",
    "                # Update status\n",
    "                self.status_var.set(f\"Successfully extracted {len(pil_frames)} frames\")\n",
    "            else:\n",
    "                messagebox.showwarning(\"Warning\", \"No valid frames could be extracted\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error extracting frames: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    \n",
    "    def extract_frames_from_registration_marks(self):\n",
    "        \"\"\"Extract frames from a contact sheet using registration mark detection.\"\"\"\n",
    "        if self.contact_sheet is None:\n",
    "            messagebox.showwarning(\"Warning\", \"No contact sheet loaded\")\n",
    "            return\n",
    "                \n",
    "        try:\n",
    "            # Convert PIL Image to OpenCV format\n",
    "            cv_image = cv2.cvtColor(np.array(self.contact_sheet), cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Create frame extractor\n",
    "            extractor = PreciseFrameExtractor()\n",
    "            \n",
    "            # Set debug mode if needed\n",
    "            extractor.set_debug_mode(self.debug_mode.get())\n",
    "            \n",
    "            # Extract frames\n",
    "            frames = extractor.extract_frames(cv_image, self.frames_per_row.get())\n",
    "            \n",
    "            if not frames:\n",
    "                messagebox.showwarning(\"Warning\", \"No frames could be extracted\")\n",
    "                return\n",
    "            \n",
    "            # Convert OpenCV frames back to PIL format\n",
    "            pil_frames = []\n",
    "            for frame in frames:\n",
    "                # Verify frame is valid before conversion\n",
    "                if frame is None or frame.size == 0 or frame.shape[0] <= 0 or frame.shape[1] <= 0:\n",
    "                    print(\"Skipping invalid frame during conversion\")\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    pil_frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                    pil_frames.append(pil_frame)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error converting frame: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            # Update the extracted frames\n",
    "            self.extracted_frames = pil_frames\n",
    "            self.current_frame_index = 0\n",
    "            \n",
    "            # Display the first frame if available\n",
    "            if self.extracted_frames:\n",
    "                self.display_current_frame()\n",
    "                # Update status\n",
    "                self.status_var.set(f\"Successfully extracted {len(pil_frames)} frames\")\n",
    "            else:\n",
    "                messagebox.showwarning(\"Warning\", \"No valid frames could be extracted\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error extracting frames: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def display_current_frame(self):\n",
    "        \"\"\"Display the current frame\"\"\"\n",
    "        if not self.extracted_frames or self.current_frame_index >= len(self.extracted_frames):\n",
    "            self.display_placeholder()\n",
    "            return\n",
    "        \n",
    "        # Get the current frame\n",
    "        frame = self.extracted_frames[self.current_frame_index]\n",
    "        \n",
    "        # Resize frame to fit canvas while maintaining aspect ratio\n",
    "        canvas_width = self.canvas.winfo_width()\n",
    "        canvas_height = self.canvas.winfo_height()\n",
    "        \n",
    "        if canvas_width <= 1 or canvas_height <= 1:\n",
    "            # Canvas not yet properly sized, use default size\n",
    "            canvas_width = 400\n",
    "            canvas_height = 400\n",
    "        \n",
    "        # Calculate scale factor to fit frame within canvas\n",
    "        frame_width, frame_height = frame.size\n",
    "        scale_width = canvas_width / frame_width\n",
    "        scale_height = canvas_height / frame_height\n",
    "        scale = min(scale_width, scale_height)\n",
    "        \n",
    "        # Resize frame\n",
    "        new_width = int(frame_width * scale)\n",
    "        new_height = int(frame_height * scale)\n",
    "        resized_frame = frame.resize((new_width, new_height), Image.LANCZOS)\n",
    "        \n",
    "        # Convert to PhotoImage\n",
    "        self.photo = ImageTk.PhotoImage(resized_frame)\n",
    "        \n",
    "        # Clear canvas and display image\n",
    "        self.canvas.delete(\"all\")\n",
    "        \n",
    "        # Calculate position to center image on canvas\n",
    "        x = (canvas_width - new_width) // 2\n",
    "        y = (canvas_height - new_height) // 2\n",
    "        \n",
    "        # Create image on canvas\n",
    "        self.canvas.create_image(x, y, anchor=tk.NW, image=self.photo)\n",
    "        \n",
    "        # Add frame number text\n",
    "        frame_text = f\"Frame {self.current_frame_index + 1}/{len(self.extracted_frames)}\"\n",
    "        self.canvas.create_text(canvas_width // 2, 20, text=frame_text, fill=\"black\", font=(\"Arial\", 12))\n",
    "    \n",
    "    def display_contact_sheet(self):\n",
    "        \"\"\"Display the loaded contact sheet\"\"\"\n",
    "        if self.contact_sheet is None:\n",
    "            self.display_placeholder()\n",
    "            return\n",
    "        \n",
    "        # Resize contact sheet to fit canvas while maintaining aspect ratio\n",
    "        canvas_width = self.canvas.winfo_width()\n",
    "        canvas_height = self.canvas.winfo_height()\n",
    "        \n",
    "        if canvas_width <= 1 or canvas_height <= 1:\n",
    "            # Canvas not yet properly sized, use default size\n",
    "            canvas_width = 400\n",
    "            canvas_height = 400\n",
    "        \n",
    "        # Calculate scale factor to fit contact sheet within canvas\n",
    "        sheet_width, sheet_height = self.contact_sheet.size\n",
    "        scale_width = canvas_width / sheet_width\n",
    "        scale_height = canvas_height / sheet_height\n",
    "        scale = min(scale_width, scale_height)\n",
    "        \n",
    "        # Resize contact sheet\n",
    "        new_width = int(sheet_width * scale)\n",
    "        new_height = int(sheet_height * scale)\n",
    "        resized_sheet = self.contact_sheet.resize((new_width, new_height), Image.LANCZOS)\n",
    "        \n",
    "        # Convert to PhotoImage\n",
    "        self.photo = ImageTk.PhotoImage(resized_sheet)\n",
    "        \n",
    "        # Clear canvas and display image\n",
    "        self.canvas.delete(\"all\")\n",
    "        \n",
    "        # Calculate position to center image on canvas\n",
    "        x = (canvas_width - new_width) // 2\n",
    "        y = (canvas_height - new_height) // 2\n",
    "        \n",
    "        # Create image on canvas\n",
    "        self.canvas.create_image(x, y, anchor=tk.NW, image=self.photo)\n",
    "        \n",
    "        # Add contact sheet text\n",
    "        self.canvas.create_text(canvas_width // 2, 20, text=\"Contact Sheet\", fill=\"black\", font=(\"Arial\", 12))\n",
    "    \n",
    "    def display_placeholder(self):\n",
    "        \"\"\"Display a placeholder when no image is loaded\"\"\"\n",
    "        # Clear canvas\n",
    "        self.canvas.delete(\"all\")\n",
    "        \n",
    "        # Get canvas dimensions\n",
    "        canvas_width = self.canvas.winfo_width()\n",
    "        canvas_height = self.canvas.winfo_height()\n",
    "        \n",
    "        if canvas_width <= 1 or canvas_height <= 1:\n",
    "            # Canvas not yet properly sized, use default size\n",
    "            canvas_width = 400\n",
    "            canvas_height = 400\n",
    "        \n",
    "        # Create placeholder text\n",
    "        self.canvas.create_text(\n",
    "            canvas_width // 2,\n",
    "            canvas_height // 2,\n",
    "            text=\"No image loaded\",\n",
    "            fill=\"gray\",\n",
    "            font=(\"Arial\", 14)\n",
    "        )\n",
    "    \n",
    "    def go_to_first_frame(self):\n",
    "        \"\"\"Go to the first frame\"\"\"\n",
    "        if self.extracted_frames:\n",
    "            self.current_frame_index = 0\n",
    "            self.display_current_frame()\n",
    "    \n",
    "    def previous_frame(self):\n",
    "        \"\"\"Go to the previous frame\"\"\"\n",
    "        if self.extracted_frames and self.current_frame_index > 0:\n",
    "            self.current_frame_index -= 1\n",
    "            self.display_current_frame()\n",
    "    \n",
    "    def next_frame(self):\n",
    "        \"\"\"Go to the next frame\"\"\"\n",
    "        if self.extracted_frames and self.current_frame_index < len(self.extracted_frames) - 1:\n",
    "            self.current_frame_index += 1\n",
    "            self.display_current_frame()\n",
    "    \n",
    "    def go_to_last_frame(self):\n",
    "        \"\"\"Go to the last frame\"\"\"\n",
    "        if self.extracted_frames:\n",
    "            self.current_frame_index = len(self.extracted_frames) - 1\n",
    "            self.display_current_frame()\n",
    "    \n",
    "    def toggle_playback(self):\n",
    "        \"\"\"Toggle animation playback\"\"\"\n",
    "        if not self.extracted_frames:\n",
    "            return\n",
    "        \n",
    "        if self.is_playing:\n",
    "            # Stop playback\n",
    "            self.is_playing = False\n",
    "            self.play_button.configure(text=\"▶\")\n",
    "            \n",
    "            # Cancel scheduled frame update\n",
    "            if self.play_after_id:\n",
    "                self.root.after_cancel(self.play_after_id)\n",
    "                self.play_after_id = None\n",
    "        else:\n",
    "            # Start playback\n",
    "            self.is_playing = True\n",
    "            self.play_button.configure(text=\"⏸\")\n",
    "            \n",
    "            # Schedule first frame update\n",
    "            self.play_animation()\n",
    "    \n",
    "    def play_animation(self):\n",
    "        \"\"\"Play the animation\"\"\"\n",
    "        if not self.is_playing or not self.extracted_frames:\n",
    "            return\n",
    "        \n",
    "        # Display current frame\n",
    "        self.display_current_frame()\n",
    "        \n",
    "        # Move to next frame or loop back to start\n",
    "        if self.current_frame_index < len(self.extracted_frames) - 1:\n",
    "            self.current_frame_index += 1\n",
    "        else:\n",
    "            self.current_frame_index = 0\n",
    "        \n",
    "        # Calculate delay based on frame rate\n",
    "        delay_ms = int(1000 / self.frame_rate.get())\n",
    "        \n",
    "        # Schedule next frame update\n",
    "        self.play_after_id = self.root.after(delay_ms, self.play_animation)\n",
    "    \n",
    "    def export_as_gif(self):\n",
    "        \"\"\"Export the extracted frames as a GIF animation\"\"\"\n",
    "        if not self.extracted_frames:\n",
    "            messagebox.showwarning(\"Warning\", \"No frames to export\")\n",
    "            return\n",
    "        \n",
    "        # Ask for save location\n",
    "        file_path = filedialog.asksaveasfilename(\n",
    "            title=\"Save GIF As\",\n",
    "            defaultextension=\".gif\",\n",
    "            filetypes=[(\"GIF files\", \"*.gif\")]\n",
    "        )\n",
    "        \n",
    "        if not file_path:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Calculate frame duration based on frame rate\n",
    "            duration_ms = int(1000 / self.frame_rate.get())\n",
    "            \n",
    "            # Save frames as GIF\n",
    "            self.extracted_frames[0].save(\n",
    "                file_path,\n",
    "                save_all=True,\n",
    "                append_images=self.extracted_frames[1:],\n",
    "                optimize=False,\n",
    "                duration=duration_ms,\n",
    "                loop=0\n",
    "            )\n",
    "            \n",
    "            self.status_var.set(f\"Saved GIF to {os.path.basename(file_path)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error saving GIF: {str(e)}\")\n",
    "    \n",
    "    def export_as_mp4(self):\n",
    "        \"\"\"Export the extracted frames as an MP4 video\"\"\"\n",
    "        if not self.extracted_frames:\n",
    "            messagebox.showwarning(\"Warning\", \"No frames to export\")\n",
    "            return\n",
    "        \n",
    "        # Ask for save location\n",
    "        file_path = filedialog.asksaveasfilename(\n",
    "            title=\"Save MP4 As\",\n",
    "            defaultextension=\".mp4\",\n",
    "            filetypes=[(\"MP4 files\", \"*.mp4\")]\n",
    "        )\n",
    "        \n",
    "        if not file_path:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Create a temporary directory for frame images\n",
    "            with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                # Save frames as PNG files\n",
    "                for i, frame in enumerate(self.extracted_frames):\n",
    "                    frame_path = os.path.join(temp_dir, f\"frame_{i:04d}.png\")\n",
    "                    frame.save(frame_path)\n",
    "                \n",
    "                # Get frame rate\n",
    "                fps = self.frame_rate.get()\n",
    "                \n",
    "                # Use FFmpeg to create MP4\n",
    "                cmd = [\n",
    "                    \"ffmpeg\",\n",
    "                    \"-y\",  # Overwrite output file if it exists\n",
    "                    \"-framerate\", str(fps),\n",
    "                    \"-i\", os.path.join(temp_dir, \"frame_%04d.png\"),\n",
    "                    \"-c:v\", \"libx264\",\n",
    "                    \"-pix_fmt\", \"yuv420p\",\n",
    "                    \"-crf\", \"23\",  # Quality (lower is better)\n",
    "                    file_path\n",
    "                ]\n",
    "                \n",
    "                # Run FFmpeg\n",
    "                subprocess.run(cmd, check=True)\n",
    "                \n",
    "                self.status_var.set(f\"Saved MP4 to {os.path.basename(file_path)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error saving MP4: {str(e)}\")\n",
    "    \n",
    "    def export_frames(self):\n",
    "        \"\"\"Export individual frames as image files\"\"\"\n",
    "        if not self.extracted_frames:\n",
    "            messagebox.showwarning(\"Warning\", \"No frames to export\")\n",
    "            return\n",
    "        \n",
    "        # Ask for save directory\n",
    "        save_dir = filedialog.askdirectory(title=\"Select Directory to Save Frames\")\n",
    "        \n",
    "        if not save_dir:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Save each frame\n",
    "            for i, frame in enumerate(self.extracted_frames):\n",
    "                frame_path = os.path.join(save_dir, f\"frame_{i+1:04d}.png\")\n",
    "                frame.save(frame_path)\n",
    "            \n",
    "            self.status_var.set(f\"Saved {len(self.extracted_frames)} frames to {os.path.basename(save_dir)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error saving frames: {str(e)}\")\n",
    "\n",
    "\n",
    "# Function to run the application\n",
    "def run_app():\n",
    "    root = tk.Tk()\n",
    "    app = AnimationApp(root)\n",
    "    root.geometry(\"800x600\")\n",
    "    root.mainloop()\n",
    "\n",
    "# Run the application when executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    run_app()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
